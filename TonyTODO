buffered iterator?

read struct: for fastQ, for fastA.
	fastQ - okay.
	fastA - ??
	
	use MPI-IO

count number of reads - every 4 lines
	indexing iterator (return positions in underlying iterator)
	and get the counts

	or create data that indexes and get the counts:  okay.

iterator with element type of iterator (for fasta?)
	essentially done via read struct.

iterator with element type of reads.
	internal to reads are 2 ptrs/iterators
	
	done.

(
iterator of iterator? with delimiter
	internal iterator has a delimiter for termination
		== search in outer iterator during the ++ phase.
	outer iterator uses a different delimiter
	internal pointers of both are incremented together
	
	essentially done.
)
	

assign read ids. (prefix scan)
	done.
	use global offset in file -> no need for communication therefore no need to read 2x.
		set in functor constructor
		done.  this means nothing needs to be kept in memory.
	use simpler iterator to search for number of records - fast but bad estimate.
		

create kmers and reverse complement - abyss idea is not bad
	buffer in transformer.
		need to update buffer during operator++()
		functor has increment and retrieve op
			done.
	reverse complement.
			done.
	
	abyss idea extended:  kmer, first half xor with reverse complement of second half.  leave second half as is.
		first part now has the symmetry.  second half allows reconstruct
		may be usable as keys for storing quality scores.
	  change in distribution?
	  	yes.  00 occurs from AA, CC, GG, TT; 01 from AC, CA, GT, TG;
	  		10 from AG, GA, CT, TC; 11 from AT, CG, GC, TA.
	  		if p(A) = p(T) = x, p(C) = p(G) = 0.5-x,
	  		
	  		then p(00) = p(11) = 4x^2 - 2x + 0.5; p(01) = p(10) = 2x - 4x^2, quadratic functions.
	  		
	  		could this create an imbalance for a region of the kmer space?
	  		 	no.  actually more even.
	
create quality score quality score
	reverse complement has same score.
	
	a simple iteration is done that computes the "Phred Score" for a kmer accurately.

generalization of iterator patterns
	1. transform iterator (1 to 1.  memory of output)
	2. filter iterator (searching.  ? to 1)
	3. buffered transform iterator (searching. ? to 1)
		ascii -> read struct
			can we get more operation inside here?
	4. buffered transform iterator (1 to 1 with memory of m previous inputs.  )
		ascii -> kmer
		quality scoring
	5. m to 1 transform iterator.  (buffered transform iterator?.  mem of output)
		packing
	6. m to n transform iterator
		unpacking (1 to n)
		packed->kmer (1 to n)
		
	2..6 need to know end of iterator
	which supports what type of base iterator?
	

mpi redistribution code.
	threading and support for streaming.	
	at least 1 thread per process for managing file input
	at least 1 thread per process for managing MPI input
	compute threads independently compute and do MPI-isend?
	
	global array - no global algorithms to go with it
	non-collective communication is good - reduce network congestion
	async communication is good - overalp compute and io
	
	semantic is still to send a block, and receive a block and do something
	send - into a sink.  iterator or buffer?
	receive - read from a src as a whole block then do someting about it - iterator or buffer?
	
	local sorting as merge operation after communication to hide sorting?

manage and buffering of reads/mpi for multicore.
	initial test complete
	compute bound due to quality score computation
		optimize - 1. use LUT .  DONE
					2. fixed point exact/approximate/directly manipulate floating point data structure.
need to change to using single MPI thread.
use MPI IO?
	
save out the index structure and reload
refactor the MPI functionality to support single node/write out to disk/external memory algos.

REDUCE CONTENTION
if few nodes, number of buffers are few and there would be high contenion between threads.
	set up with number of buffers = multiple of threads and number of procs.  
	and map multiple buffers to a single proc. DONE
		some improvements but not huge.  need to figure out how to lock smaller regions.  compute threads are spending a lot of time waiting.
		

try using the "file" as the queue, avoid master slave paradigm in OMP
	DONE.  no visible changes on a single node.
	
	
scaling is good from 2 to 16 nodes on CyEnce.  32 node not as good. 
	compute times still scale linearly.
	perhaps it's the flushing part (sequential, no async send)
	
	
	
Factor out MPI Buffer and set it up to
	1. as multi buffer that works with MPI_AllToAll
	2. genericize to support other backends (e.g. file system, MPI-IO, etc.). 
	
ERROR: try with each thread hold separate buffers:  some buffers are not cleared.  need to fix.  DONE
ERROR: threads sharing buffers: deadlock now at exit - termination of MPI processes.  DONE

each thread holding separate buffer is now working.  not yet profiled.  the task based approach appears fast but need to validate to be correct.
the omp version is not as performant.  not sure why.

for now, refactor to make code more maintainable.

ERROR: double free or buffer corruption, segV, abort, memory corruption, etc.  only happens with master-slave version.
	turn on thread safety -> working okay.  no memory leak.
	this is probably due to wrong thread id, and subsequently wrong bin computation, then multiple threads writing to the same buffer.
	change signature of XorModulus (hashfunction to get threadid at call time.  make the KmerIndexGenerators produce the threadid.
	this works better because we can't tell the assignment of tasks until they are scheduled onto the node.
	
	fixed.  performance improved compared to before refactoring.
	

NEXT TODO:
	parallel flush?  or use Alltoall?
	auto-tune locking vs replicated buffer threshold.
	further refactoring (now in test_threads)  
	testing version WITHOUT quality scores.  DONE.  faster.  < 1 sec for test data.  ~ 150 sec for 1000genome data.  with quality score:  1.56s and 283 sec.
	version that counts kmers.
	Flexible K for kmer - important for testing?
	testing 1 mpi proc, 1 ... c cores/threads, etc
		results: single node, 1 thread, 1 proc - fast.  superlinear slow down as more threads are used.
		results: 		sublinear speed up as more procs are used.
		WHY?  this is non threadsafe.  This needs to be profiled.
		
		code is not optimal - MPI off case is doing a lot more work then needed.
			OMP off case (thread = 1) is still dispatching work.  MPI off case (p = 1) is still using send/receive.

	One "oops": was not actually copying the read.
		testing - not the bottleneck
		
	problem was with how the threads are scheduled and syncs
		parallel for is fastest - get some speed up going towards 2x on 4 core desktop
		demand driven on peered worker threads - slower as more threads are added.  5x slower
		demand driven master slave - slowest - 5x slower than demand driven peered
		ISSUE:  too many tasks.  make each task work more.  this is with simple test code.
			master slave, demand driven scheduling, with chunk size of 32 to 64 is fine.
			thread scalability is okay. to about 3x...
		at least now scaling.  though not perfect.
			comparisons:  sequential vs peers with demand driven, vs M/S with demand driven, vs par for with dynamic/guided partitioning.
			
		

Each thread owning its own set of buffers - if 1000 procs, 16 threads each, 8MB each buffer, -> 128G.  need smarter locking.


Need to use MPI persistent communication. 
	
major improvement when removing MAP_POPULATE.  else file mmap time in tens of seconds.
	
query...


random sequence generator

// support queries for read id, read positions, and count


IndexStruct:  aligned to 8 bytes, so even using float - 24 bytes.
	need MPI derived data types to reduce memory usage.



spaced seeds?

OpenMP version
test remote file open.
FASTA


simple kmer counting. 
