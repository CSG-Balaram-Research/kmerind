buffered iterator?

read struct: for fastQ, for fastA.
	fastQ - okay.
	fastA - ??
	
	use MPI-IO

count number of reads - every 4 lines
	indexing iterator (return positions in underlying iterator)
	and get the counts

	or create data that indexes and get the counts:  okay.

iterator with element type of iterator (for fasta?)
	essentially done via read struct.

iterator with element type of reads.
	internal to reads are 2 ptrs/iterators
	
	done.

(
iterator of iterator? with delimiter
	internal iterator has a delimiter for termination
		== search in outer iterator during the ++ phase.
	outer iterator uses a different delimiter
	internal pointers of both are incremented together
	
	essentially done.
)
	

assign read ids. (prefix scan)
	done.
	use global offset in file -> no need for communication therefore no need to read 2x.
		set in functor constructor
		done.  this means nothing needs to be kept in memory.
	use simpler iterator to search for number of records - fast but bad estimate.
		

create kmers and reverse complement - abyss idea is not bad
	buffer in transformer.
		need to update buffer during operator++()
		functor has increment and retrieve op
			done.
	reverse complement.
			done.
	
	abyss idea extended:  kmer, first half xor with reverse complement of second half.  leave second half as is.
		first part now has the symmetry.  second half allows reconstruct
		may be usable as keys for storing quality scores.
	  change in distribution?
	  	yes.  00 occurs from AA, CC, GG, TT; 01 from AC, CA, GT, TG;
	  		10 from AG, GA, CT, TC; 11 from AT, CG, GC, TA.
	  		if p(A) = p(T) = x, p(C) = p(G) = 0.5-x,
	  		
	  		then p(00) = p(11) = 4x^2 - 2x + 0.5; p(01) = p(10) = 2x - 4x^2, quadratic functions.
	  		
	  		could this create an imbalance for a region of the kmer space?
	  		 	no.  actually more even.
	
create quality score quality score
	reverse complement has same score.
	
	a simple iteration is done that computes the "Phred Score" for a kmer accurately.

generalization of iterator patterns
	1. transform iterator (1 to 1.  memory of output)
	2. filter iterator (searching.  ? to 1)
	3. buffered transform iterator (searching. ? to 1)
		ascii -> read struct
			can we get more operation inside here?
	4. buffered transform iterator (1 to 1 with memory of m previous inputs.  )
		ascii -> kmer
		quality scoring
	5. m to 1 transform iterator.  (buffered transform iterator?.  mem of output)
		packing
	6. m to n transform iterator
		unpacking (1 to n)
		packed->kmer (1 to n)
		
	2..6 need to know end of iterator
	which supports what type of base iterator?
	

mpi redistribution code.
	threading and support for streaming.	
	at least 1 thread per process for managing file input
	at least 1 thread per process for managing MPI input
	compute threads independently compute and do MPI-isend?
	
	global array - no global algorithms to go with it
	non-collective communication is good - reduce network congestion
	async communication is good - overalp compute and io
	
	semantic is still to send a block, and receive a block and do something
	send - into a sink.  iterator or buffer?
	receive - read from a src as a whole block then do someting about it - iterator or buffer?
	
	local sorting as merge operation after communication to hide sorting?

manage and buffering of reads/mpi for multicore.
	initial test complete
	compute bound due to quality score computation
		optimize - 1. use LUT .  DONE
					2. fixed point exact/approximate/directly manipulate floating point data structure.
need to change to using single MPI thread.
use MPI IO?
	
save out the index structure and reload
refactor the MPI functionality to support single node/write out to disk/external memory algos.

REDUCE CONTENTION
if few nodes, number of buffers are few and there would be high contenion between threads.
	set up with number of buffers = multiple of threads and number of procs.  
	and map multiple buffers to a single proc. DONE
		some improvements but not huge.  need to figure out how to lock smaller regions.  compute threads are spending a lot of time waiting.
		

try using the "file" as the queue, avoid master slave paradigm in OMP
	DONE.  no visible changes on a single node.
	
	
scaling is good from 2 to 16 nodes on CyEnce.  32 node not as good. 
	compute times still scale linearly.
	perhaps it's the flushing part (sequential, no async send)
	
	
	
Factor out MPI Buffer and set it up to
	1. as multi buffer that works with MPI_AllToAll
	2. genericize to support other backends (e.g. file system, MPI-IO, etc.). 
	
ERROR: try with each thread hold separate buffers:  some buffers are not cleared.  need to fix.  DONE
ERROR: threads sharing buffers: deadlock now at exit - termination of MPI processes.  DONE

each thread holding separate buffer is now working.  not yet profiled.  the task based approach appears fast but need to validate to be correct.
the omp version is not as performant.  not sure why.

for now, refactor to make code more maintainable.

ERROR: double free or buffer corruption, segV, abort, memory corruption, etc.  only happens with master-slave version.
	turn on thread safety -> working okay.  no memory leak.
	this is probably due to wrong thread id, and subsequently wrong bin computation, then multiple threads writing to the same buffer.
	change signature of XorModulus (hashfunction to get threadid at call time.  make the KmerIndexGenerators produce the threadid.
	this works better because we can't tell the assignment of tasks until they are scheduled onto the node.
	
	fixed.  performance improved compared to before refactoring.
	

NEXT TODO:
	parallel flush?  or use Alltoall?
	auto-tune locking vs replicated buffer threshold.
	further refactoring (now in test_threads)  
	testing version WITHOUT quality scores.  DONE.  faster.  < 1 sec for test data.  ~ 150 sec for 1000genome data.  with quality score:  1.56s and 283 sec.
	version that counts kmers.
	Flexible K for kmer - important for testing?
	testing 1 mpi proc, 1 ... c cores/threads, etc
		results: single node, 1 thread, 1 proc - fast.  superlinear slow down as more threads are used.
		results: 		sublinear speed up as more procs are used.
		WHY?  this is non threadsafe.  This needs to be profiled.
		
		code is not optimal - MPI off case is doing a lot more work then needed.
			OMP off case (thread = 1) is still dispatching work.  MPI off case (p = 1) is still using send/receive.

	One "oops": was not actually copying the read.
		testing - not the bottleneck
		
	problem was with how the threads are scheduled and syncs
		parallel for is fastest - get some speed up going towards 2x on 4 core desktop
		demand driven on peered worker threads - slower as more threads are added.  5x slower
		demand driven master slave - slowest - 5x slower than demand driven peered
		ISSUE:  too many tasks.  make each task work more.  this is with simple test code.
			master slave, demand driven scheduling, with chunk size of 32 to 64 is fine.
			thread scalability is okay. to about 3x...
		at least now scaling.  though not perfect.
			comparisons:  sequential vs peers with demand driven, vs M/S with demand driven, vs par for with dynamic/guided partitioning.
			with appropriate chunking (on desktop with i5 4 cores, chunk size of 32 to 128), all parallel strategies are about the same.
			
	so how to apply this to a file?   chunked reads.
		one idea:  read multiple items.  however, reading an item is relatively slow and this part would be in critical sec
		another idea:  have an iterator that buffers some portion of underlying data.
			issue:  what is appropriate container?
			solution:  start treating file as a sequence of bytes, not as some multibyte data type
		another idea:  have a CHUNKING ITERATOR, and do search (in critical section) for the appropriate
			end point within some distance from starting point.  then copy that region, and create high level iterators over these chunks.
			copy requires knowledge of how to copy - assume BYTE ARRAY.	
			
			
4/22/2014
		reorganize fastq_iterator and fastq_loader.
			search for start of read should be move into fastq_iterator, alongside parser
			align_to_sequence is what?
			fastq_loader used to find PROC level start and end, and to provide chunking support via ChunkIterator
			then chunks are extracted on demand from the underlying iterator to generate another iterator that is shorter
				evaluate once pre critical section by each core.
				this belongs to file_loader?
			finally ChunkIterater is then used to initialize fastq_iterator for parsing into reads. (which are then transformed into kmers)
			
		update fileloader to be more self contained, and support parallel loading given an MPI comm.  DONE.
			put interface on file_loader to allow loading in chunks. TODO.
4/25/2014
		refactoring is almost done.  file loader is less of a super class now.   fastq_loader is now a functor for partitioning boundary adjustment only.
		TODO: chunks.
		TODO: change: no qual and no mpi tests.
		
4/30/2014
		if chunk too short, can't find any, should throw an exception.  caller handles exception and decide what to do - use the range.start or range.end
		
		
Q: shared mem map better or single?
		
Each thread owning its own set of buffers - if 1000 procs, 16 threads each, 8MB each buffer, -> 128G.  need smarter locking.
	

Need to use MPI persistent communication. 
	
major improvement when removing MAP_POPULATE.  else file mmap time in tens of seconds.
	
query...


random sequence generator

// support queries for read id, read positions, and count


IndexStruct:  aligned to 8 bytes, so even using float - 24 bytes.
	need MPI derived data types to reduce memory usage.



spaced seeds?

OpenMP version
test remote file open.
FASTA


simple kmer counting. 






optimization:  may want to have a way to mark a variable as requiring synchronization, and change OMP pattern.


try avoiding iterator comparison.  user offsets instead.  May or may not help depend on compiler optimization.


refactoring
introduce partitioner,
	runnable
	runner
	task
		with compute op, src (e.g. file), and dest (e.g. mpibuffer)
		e.g. index generator.
	rework file_loader, and reintroduce fastq_loader.
	
	
TODO:  5/23.

Bug in gtest.  if single parameter constructor is used with ASSERT_THROW or ASSERT_NO_THROW, it will not find the correct constructor during compilation.
	workaround:  user "new Class(param)" or "(Class(param))"


integration testing.

Move:  useful when there is allocation of memory, even if implicit.
	std::move used to create a rvalue reference (&&).  
	std::forward used to do similar, but to forward a function parameter. (used when parameter type is a rvalue reference to type parameter).
	std::swap
	swap on containers, including std::string
	return reference instead of lvalue
	
Move constructor and move assignment operator for:
	utils		- none
	partition 	- none (too simple)
	iterators	- TBD
	io			-
		io_exception	- done. move for speed.
		MPISendBuffer/MPISendBuffers  - TODO move for correctness
		file_loader		- done. move for correctness
		fastq_loader	- done. no instance variable.  move reuses superclass stuff.  move for correctness
		fastq_iterator	- TBD copy construct may be fine...  ???
		data_block		- done.  move for correctness
	concurrent	- TODO
		task			- should move for correctness
		runnable		- nothing
		runner			- nothing
		sequential_runner	- has queue. should move for correctness
		omp/mpi			- should move for correctness.
		mixed_omp		- should move for correctness.
	index		- TBD
		kmer_index_element
		
		
		
use of move semantics - TBD
	io
		MPISendBuffer/MPISendBuffers
		FileLoader
		FASTQLoader
	index
	concurrent


Chagne FASTQIterator to use ranges for sequence and quality, and keep only 1 iterator.
Change Range to have different subclasses.



testing:  concurrentIO - back to working with some exceptions:
	FASTQ, FASTQIter2, FASTQIterNoQual are failing for block parallel - errors.  but numeric results are still fine.
		theory:  the last chunk in the partition is a partial, and there is no @ in that chunk.  previous chunk search return the end of the partition, but current chunk search is having problem.  not sure why that asymmetry
		FIXED by adding a check (if can't find a "start") for the end of the partition range.  if at end of partition range and not found a start, return the end of partition range.
	BLOCK PARALLEL is not generating same numeric results for mmap, fileloader, fileloader atomic - 
		1 problem was due to boundaries; FIXED.  another due to numeric precision.
		
		
index generation is back up and running.  however, scalability is still problem.
	1 thread: .88 sec on small dataset, quality compute on.
	2 - 4 threads, about 1.44 to 1.41 s.
	
	with MPI:  2 mpi with 2 threads each - 0.7 sec.
		4 mpi with 1 thread each - fail with segv.
		
	
problem:
	with 1 thread, MPI, deadlock.
		problem: 2 different MPI procs could get into a deadlock 
			
			another explanation:
				t0:  proc 0 thread t sender buffer for proc 1 full.  isend to proc 1
				t1:  proc 0 thread t sender buffer for proc 1 full.  waiting for t0 send to complete before isend to proc 1. - blocking.
				t2:  proc 1 thread 0 receiver iprobe successful.  enters receive from t0.  waiting for proc 0 - blocking. 
				
		using MPI_Test instead of MPI_Wait reduces the problem but does not solve it.  MPI_Test ends up still in a busywait loop so effectively it's same as MPI_Wait.
			proper fix:  sending needs its own thread, along with a thread-safe buffer function.
			symmetry - receiver should have a thread-safe retrieve function, and live in its own thread?
			
		GOOD TIME TO create a single thread for MPI communication.
			need a few queues - for send buffer that are ready to send, and for receive buffers to be put into the index. 
TODO:	threadsafe queue - correct but may be slow.
		REPLACE LATER.  for now, it may be  fine for buffer management with MPI.  Need multiple producer, single/multiple consumer.
			
			
		there may also be a a data hazard problem - evidence: sometime deadlock, sometimes segv, sometime works.
	with 2+ threads, MPI, fine.
		
		
Created a single thread for MPI communication.
	having trouble with compute thread consistency
	
		
		
TODO:
	1. query API 
	2. better runtime api
	3. testing query with/out mpi, with/out omp from 1 code base
	4. mpi persistent communication - buffer sizes varies, and performance gain for large packets is small - don't worry about it.
	5. iterator dereferencing, functor and copy/move construction:  need a way to make clear what CAN and CANNOT be moved from iterator, i.e. repeated calls to dereference operator should be stable.
	6. precompute all.  bucket. mpi all-to-all. hash 